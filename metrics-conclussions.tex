Lo primero que me ha sorprendido al ver los números finales es que se ha amortizado el tiempo dedicado a hacer las pruebas unitarias. He experimentado esta amortización en proyectos más grandes, pero no me esperaba que en un proyecto de esta escala las horas dedicadas a solucionar errores fuesen a ser mayores a las horas dedicadas a realizar pruebas untiarias. Hay que tener en cuenta que, tal y como se comenta en la introducción de \nameref{chap:metrics}, este experimento ha sido muy limitado y hay que coger con pinzas estos resultados, pero ya nos hacemos a la idea que en ocasiones e incluso para proyectos pequeños, hacer pruebas unitarias puede salir rentable.

Para hacer justicia a la verdad, el tiempo total dedicado a realizar las pruebas automáticas ha sido de 7 horas. Sin embargo, con el descuento que nos hace el marco de trabajo con toda la configuración del entorno ha salido rentable. En proyectos más grandes esto es mucho más difícil de medir, pero los errores tienden a escalar en profundidad y suelen ser más difíciles de depurar. Además, a esto habría que sumar pruebas de integración y funcionales, que no se han realizado por la simplicidad del proyecto.

Otro dato que me ha sorprendido es la cantidad de errores que se han producido. 20 errores en un código de aproximadamente 5600 líneas de código implica a un error cada 280 líneas de código. Es de esperar que a este ritmo, si se comienza una prueba de concepto sin código de calidad, a la hora de realizar el escalado cualquiera de estos muchos errores va a pasar factura más adelante. Los errores predecidos eran 10, así que aunque el proyecto sea bien conocido y de dimensiones limitadas, los errores están a la orden del día. En un proyecto de prueba, podríamos llegar a esperar un error cada 150 líneas de código. Esto hace mucho más acuciante la necesidad de utilizar código de calidad.

El tiempo que nos ha ahorrado el marco de trabajo ha sido de 3 horas, pero no es un dato muy representativo dado que gran parte de la potencia del marco no se ha utilizado. No se ha utilizado ningún servidor de integración contínua ni se ha desplegado el proyecto en ningún sitio, así que esas 3 horas de ahorro se pueden considerar como el mínimo. Además, estas 3 horas son lo que he tardado yo en configurar el proyecto, que soy la misma persona que ha realizado el marco de trabajo y, por tanto, se ha estudiado numerosas posibles configuraciones y comprende las interacciones de Express, Webpack, React y GraphQL con bastante profundidad. Una persona que está explorando un campo nuevo puede dedicar incluso una semana entera a configurar el proyecto, así que este ahorro no ha quedado bien reflejado en el experimento.

Así que, como conclusión final del experimento, este marco de trabajo ha sido muy positivo incluso para proyectos pequeños porque alivia la carga de configuración del proyecto, tal y como se pretendía, preparando el entorno para la realización de pruebas automáticas y evitando esos 20 errores que podrían costar una fortuna si se encuentran una vez el proyecto ha escalado y está en producción.

Aun así, como el experimento ha sido limitado queda por comprobar si realmente en un caso de uso real este marco de trabajo es de utilidad. Y la única forma de comprobarlo es con tiempo y esperando la retroalimentación de los usuarios del marco. La apuesta, sin embargo, es que este marco va a ser de gran utilidad siempre y cuando el compromiso de realizar código de calidad sea real.
